{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FMU2YpOeNvxB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMU2YpOeNvxB",
        "outputId": "fe54c7fd-5ca5-4f2c-84ca-812eba6e5ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# for Google Colab\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir('/content/drive/MyDrive/c_sc/Project/programm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d620b0c",
      "metadata": {
        "id": "8d620b0c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "import cv2\n",
        "import os\n",
        "from os import listdir\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from timeit import default_timer as timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xWWyH8rSH5aE",
      "metadata": {
        "id": "xWWyH8rSH5aE"
      },
      "outputs": [],
      "source": [
        "# Import images chosen to be the train data\n",
        "\n",
        "image_folder = r'data_train/'\n",
        "images = []\n",
        "for filename in sorted(listdir(image_folder)):\n",
        "    img = cv2.imread((os.path.join(image_folder, filename)))\n",
        "    if img is not None:\n",
        "        img = cv2.medianBlur(img, 7)\n",
        "        images.append(img)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].grid(False)\n",
        "ax[0].imshow(images[0][:,:,::-1])\n",
        "ax[1].grid(False)\n",
        "ax[1].imshow(images[1][:,:,::-1]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zZIvx6FgXZdw",
      "metadata": {
        "id": "zZIvx6FgXZdw"
      },
      "outputs": [],
      "source": [
        "XX = [] # list of lists that are images\n",
        "for i in images:\n",
        "    height = i.shape[0]\n",
        "    width = i.shape[1]\n",
        "    ordered_positions = np.array(np.meshgrid(np.arange(height), np.arange(width))).T.reshape(-1, 2)\n",
        "\n",
        "    X = []\n",
        "    for j in ordered_positions:\n",
        "        X.append(i[j[0], j[1], ::])\n",
        "\n",
        "    X = np.array(X, copy=False)\n",
        "    XX.append(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "klQMGrxmeGu6",
      "metadata": {
        "id": "klQMGrxmeGu6"
      },
      "outputs": [],
      "source": [
        "# Elbow method\n",
        "\n",
        "model_elb = KMeans(random_state=0, n_init=\"auto\")\n",
        "visualizer = KElbowVisualizer(model_elb, k=(2, 10), timings=False)\n",
        "visualizer.fit(XX[0])\n",
        "visualizer.poof();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4702a37b",
      "metadata": {
        "id": "4702a37b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# K-means clustering\n",
        "num_clusters = 2  # cluster quantity\n",
        "\n",
        "predictions_all = []\n",
        "\n",
        "for i in XX:\n",
        "\n",
        "    model = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=300, random_state=2, n_init=1).fit(i)\n",
        "    labels = model.labels_\n",
        "\n",
        "    # Transform retrieved data into image like form for visualisation and following labeling\n",
        "\n",
        "    predictions_map = np.zeros(labels.shape).reshape(height, width)\n",
        "    for (y, x), pred in zip(ordered_positions, labels):\n",
        "        predictions_map[y, x] = pred\n",
        "\n",
        "    predictions_all.append(predictions_map)\n",
        "\n",
        "predictions_map = np.concatenate((predictions_all[0], predictions_all[1]), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99a1a430",
      "metadata": {
        "id": "99a1a430",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Visual analysis\n",
        "img_conc = np.concatenate((images[0], images[1]), axis=0)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 8))\n",
        "ax1.imshow(img_conc[:,:,::-1]); #img_rgb\n",
        "sns.heatmap(predictions_map, ax=ax2)\n",
        "ax1.grid(False)\n",
        "ax1.set_title('Source')\n",
        "ax2.axis('off')\n",
        "ax2.set_title(f'Predictions n={num_clusters}')\n",
        "plt.subplots_adjust(wspace=0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7658963",
      "metadata": {
        "id": "b7658963"
      },
      "outputs": [],
      "source": [
        "d = {'0': 'background',\n",
        "    '1': 'damaged forest',\n",
        "    }\n",
        "regions = pd.Series(d)\n",
        "print(regions)\n",
        "print('classes -', np.unique(predictions_map))\n",
        "type(predictions_map), predictions_map.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e034b2b2",
      "metadata": {
        "id": "e034b2b2"
      },
      "source": [
        "С помощью библиотеки OpenCV произведем операции эрозии и дилатации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d0207d7",
      "metadata": {
        "id": "2d0207d7"
      },
      "outputs": [],
      "source": [
        "# Creating Deforested area class mask\n",
        "mask = predictions_map.copy()\n",
        "mask[mask == 1] = 255\n",
        "mask = np.uint8(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b0acb2b",
      "metadata": {
        "id": "0b0acb2b"
      },
      "outputs": [],
      "source": [
        "# Erosion and dilation functions\n",
        "\n",
        "def erode(mask, kernel_val=3, iters=1):\n",
        "    kernel = np.ones((kernel_val, kernel_val), np.uint8)\n",
        "    mask = cv2.erode(mask, kernel, iterations=iters)\n",
        "    eroded_mask = mask.copy()\n",
        "    return eroded_mask\n",
        "\n",
        "def dilate(mask, kernel_val=3, iters=1):\n",
        "    kernel = np.ones((kernel_val, kernel_val), np.uint8)\n",
        "    dilated_mask = cv2.dilate(mask, kernel, iterations=iters)\n",
        "    return dilated_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "052218fd",
      "metadata": {
        "id": "052218fd"
      },
      "outputs": [],
      "source": [
        "# Manual mask modifying with erosion and dilation operations\n",
        "\n",
        "img_gray = cv2.cvtColor(img_conc, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "def nothing(x):\n",
        "    pass\n",
        "\n",
        "cv2.namedWindow('controls', cv2.WINDOW_NORMAL)\n",
        "cv2.createTrackbar('erode_matr', 'controls', 3, 10, nothing)\n",
        "cv2.createTrackbar('erode_itr', 'controls', 0, 10, nothing)\n",
        "cv2.createTrackbar('dilate_matr', 'controls', 3, 10, nothing)\n",
        "cv2.createTrackbar('dilate_itr', 'controls', 0, 10, nothing)\n",
        "cv2.createTrackbar('erode_matr_1', 'controls', 3, 10, nothing)\n",
        "cv2.createTrackbar('erode_itr_1', 'controls', 0, 10, nothing)\n",
        "cv2.createTrackbar('dilate_matr_1', 'controls', 3, 10, nothing)\n",
        "cv2.createTrackbar('dilate_itr_1', 'controls', 0, 10, nothing)\n",
        "\n",
        "while(1):\n",
        "\n",
        "    e_matr = int(cv2.getTrackbarPos('erode_matr', 'controls'))\n",
        "    e_itr = int(cv2.getTrackbarPos('erode_itr', 'controls'))\n",
        "    d_matr = int(cv2.getTrackbarPos('dilate_matr', 'controls'))\n",
        "    d_itr = int(cv2.getTrackbarPos('dilate_itr', 'controls'))\n",
        "    e_matr_1 = int(cv2.getTrackbarPos('erode_matr_1', 'controls'))\n",
        "    e_itr_1 = int(cv2.getTrackbarPos('erode_itr_1', 'controls'))\n",
        "    d_matr_1 = int(cv2.getTrackbarPos('dilate_matr_1', 'controls'))\n",
        "    d_itr_1 = int(cv2.getTrackbarPos('dilate_itr_1', 'controls'))\n",
        "\n",
        "    mask_res_1 = erode(mask, kernel_val=e_matr, iters=e_itr)\n",
        "    mask_res_2 = dilate(mask_res_1, d_matr, d_itr)\n",
        "    mask_res_3 = erode(mask_res_2, e_matr_1, e_itr_1)\n",
        "    mask_res_4 = dilate(mask_res_3, d_matr_1, d_itr_1)\n",
        "\n",
        "    mask_res_4_inv = cv2.bitwise_not(mask_res_4)\n",
        "\n",
        "    img_new = cv2.bitwise_and(img_conc, img_conc, mask=mask_res_4)\n",
        "    img_gray_new = cv2.bitwise_and(img_gray, img_gray, mask=mask_res_4_inv)\n",
        "\n",
        "    out = cv2.add(img_new, cv2.cvtColor(img_gray_new, cv2.COLOR_GRAY2BGR))\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(mask_res_4_inv, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "    cv2.drawContours(out, contours, -1, (0, 0, 255), 1)\n",
        "\n",
        "    text = f'contours q-ty = {str(len(contours))}'\n",
        "    fontScale = 1\n",
        "    fontFace = cv2.FONT_HERSHEY_COMPLEX\n",
        "    fontColor = (0, 255, 0)\n",
        "    fontThickness = 2\n",
        "    cv2.putText(out, text, (0, 60), fontFace, fontScale, fontColor, fontThickness, cv2.LINE_AA);\n",
        "\n",
        "    cv2.namedWindow('img_d', cv2.WINDOW_NORMAL)\n",
        "    cv2.namedWindow('out', cv2.WINDOW_NORMAL)\n",
        "    cv2.imshow('img_d', mask_res_4)\n",
        "    cv2.imshow('out', out)\n",
        "\n",
        "    k = cv2.waitKey(1) & 0xFF\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "cv2.waitKey(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KD1zb8aRGu8s",
      "metadata": {
        "id": "KD1zb8aRGu8s"
      },
      "outputs": [],
      "source": [
        "# The alternative way of clustering by track bars at HSV color space\n",
        "\n",
        "img_track = cv2.imread(r'data_train/1image1.JPG')\n",
        "img_track = cv2.medianBlur(img_track, 7)\n",
        "img_hsv = cv2.cvtColor(img_track, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "def nothing(x):\n",
        "    pass\n",
        "\n",
        "cv2.namedWindow('controls', cv2.WINDOW_NORMAL)\n",
        "cv2.createTrackbar('H_lower','controls', 0, 179, nothing)\n",
        "cv2.createTrackbar('S_lower','controls', 0, 255, nothing)\n",
        "cv2.createTrackbar('V_lower','controls', 0, 255, nothing)\n",
        "cv2.createTrackbar('H_upper','controls', 0, 179, nothing)\n",
        "cv2.createTrackbar('S_upper','controls', 0, 255, nothing)\n",
        "cv2.createTrackbar('V_upper','controls', 0, 255, nothing)\n",
        "\n",
        "while(1):\n",
        "\n",
        "    H_l = int(cv2.getTrackbarPos('H_lower', 'controls'))\n",
        "    H_u = int(cv2.getTrackbarPos('H_upper', 'controls'))\n",
        "    S_l = int(cv2.getTrackbarPos('S_lower', 'controls'))\n",
        "    S_u = int(cv2.getTrackbarPos('S_upper', 'controls'))\n",
        "    V_l = int(cv2.getTrackbarPos('V_lower', 'controls'))\n",
        "    V_u = int(cv2.getTrackbarPos('V_upper', 'controls'))\n",
        "\n",
        "    lower = np.array([H_l, S_l, V_l])\n",
        "    upper = np.array([H_u, S_u, V_u])\n",
        "\n",
        "    mask = cv2.inRange(img_hsv, lower, upper)\n",
        "\n",
        "    cv2.namedWindow('mask', cv2.WINDOW_NORMAL)\n",
        "    cv2.imshow('mask', mask)\n",
        "\n",
        "    k = cv2.waitKey(1) & 0xFF\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "cv2.waitKey(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc52fda0",
      "metadata": {
        "id": "dc52fda0"
      },
      "outputs": [],
      "source": [
        "# Modified mask is saved to file\n",
        "# np.save('mask_2tp_morph.npy', mask_res_4)\n",
        "pred_map = np.load('mask_2tp_morph.npy')  # load mask\n",
        "plt.imshow(pred_map, 'gray');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74c01651",
      "metadata": {
        "id": "74c01651"
      },
      "outputs": [],
      "source": [
        "# Changing labels shape\n",
        "\n",
        "pred_map[pred_map == 255] = 1\n",
        "np.unique(pred_map)\n",
        "\n",
        "X = np.concatenate((XX[0], XX[1]), axis=0)\n",
        "\n",
        "height_1 = img_conc.shape[0] #сдвоенное изобр\n",
        "width_1 = img_conc.shape[1]\n",
        "ordered_positions_1 = np.array(np.meshgrid(np.arange(height_1), np.arange(width_1))).T.reshape(-1, 2)\n",
        "\n",
        "labels_new = []\n",
        "for i in ordered_positions_1:\n",
        "    labels_new.append(pred_map[i[0], i[1]])\n",
        "labels_new = np.array(labels_new, copy=False)\n",
        "print(labels_new.shape), print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c669f19",
      "metadata": {
        "id": "3c669f19"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)         # data normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tIdjpCU5TyeG",
      "metadata": {
        "id": "tIdjpCU5TyeG"
      },
      "outputs": [],
      "source": [
        "# Evaluating the quality of the models predictions:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "classifiers = [MLPClassifier(max_iter=200), GaussianNB(), KNeighborsClassifier(n_neighbors=3)]\n",
        "evaluation_dict_all = []\n",
        "\n",
        "X_train, X_test, labels_train, labels_test = train_test_split(X, labels_new, test_size=0.3, random_state = True, shuffle=True)\n",
        "\n",
        "for classifier in classifiers:\n",
        "\n",
        "    start = timer()\n",
        "    model = classifier\n",
        "    model.fit(X_train, labels_train)\n",
        "    labels_pred = model.predict(X_test)\n",
        "    end = timer()\n",
        "    print(end - start)\n",
        "\n",
        "    cm = confusion_matrix(labels_test, labels_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "\n",
        "    score = model.score(X_test, labels_test)\n",
        "    print(score)\n",
        "\n",
        "    TN = cm[0][0]\n",
        "    FP = cm[0][1]\n",
        "    FN = cm[1][0]\n",
        "    TP = cm[1][1]\n",
        "\n",
        "    # Sensitivity, hit rate, recall, or true positive rate\n",
        "    TPR = TP/(TP+FN)\n",
        "    # Specificity or true negative rate\n",
        "    TNR = TN/(TN+FP)\n",
        "    # Precision or positive predictive value\n",
        "    PPV = TP/(TP+FP)\n",
        "    # Negative predictive value\n",
        "    NPV = TN/(TN+FN)\n",
        "    # Fall out or false positive rate\n",
        "    FPR = FP/(FP+TN)\n",
        "    # False negative rate\n",
        "    FNR = FN/(TP+FN)\n",
        "    # False discovery rate\n",
        "    FDR = FP/(TP+FP)\n",
        "    # F1 metric\n",
        "    F1 = 2 * ((PPV * TPR) / (PPV + TPR))\n",
        "    # Overall accuracy\n",
        "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    evaluation_dict = {'FP': FP,\n",
        "                       'FN': FN,\n",
        "                       'TP': TP,\n",
        "                       'TN': TN,\n",
        "                       'TPR': TPR,\n",
        "                       'TNR': TNR,\n",
        "                       'PPV': PPV,\n",
        "                       'NPV': NPV,\n",
        "                       'FPR': FPR,\n",
        "                       'FNR': FNR,\n",
        "                       'FDR': FDR,\n",
        "                       'F1': F1,\n",
        "                       'ACC/Score': ACC\n",
        "                       }\n",
        "\n",
        "    evaluation_dict_all.append(evaluation_dict)\n",
        "\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.grid(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b142fc9",
      "metadata": {
        "id": "6b142fc9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Learning the classifier with fool train data\n",
        "\n",
        "\n",
        "#cls = MLPClassifier(max_iter=200)\n",
        "#cls.fit(X, labels_new)\n",
        "#joblib.dump(cls, 'MLP_2cl_morph_nrml.pkl') # save the trained model to file\n",
        "cls = joblib.load('MLP_2cl_morph_nrml.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hDXfw7QC1ddn",
      "metadata": {
        "id": "hDXfw7QC1ddn"
      },
      "outputs": [],
      "source": [
        "cls = KNeighborsClassifier(n_neighbors=3)\n",
        "cls.fit(X, labels_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IVXWZHTkpuMs",
      "metadata": {
        "id": "IVXWZHTkpuMs"
      },
      "outputs": [],
      "source": [
        "cls = GaussianNB()\n",
        "cls.fit(X, labels_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0776f8e",
      "metadata": {
        "id": "a0776f8e"
      },
      "outputs": [],
      "source": [
        "# Process the whole dataset\n",
        "\n",
        "image_folder = r'data/'\n",
        "images = []\n",
        "for filename in listdir(image_folder):\n",
        "    img = cv2.imread(os.path.join(image_folder, filename))\n",
        "    if img is not None:\n",
        "        images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "434470d9",
      "metadata": {
        "id": "434470d9",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "start = timer()\n",
        "j = 1\n",
        "k = 2\n",
        "square = []\n",
        "predictions_map_test_all = []\n",
        "\n",
        "fig = plt.figure(figsize=(17, 80))\n",
        "\n",
        "for image in images:\n",
        "    ax = fig.add_subplot(15, 2, j)\n",
        "    ax1 = fig.add_subplot(15, 2, k)\n",
        "\n",
        "    img_2 = image\n",
        "    assert img_2 is not None, ('not found')\n",
        "    height = img_2.shape[0]\n",
        "    width = img_2.shape[1]\n",
        "    img_2  = cv2.medianBlur(img_2, 7)\n",
        "    ordered_positions_2 = np.array(np.meshgrid(np.arange(height), np.arange(width))).T.reshape(-1, 2)\n",
        "    X_2 = []\n",
        "    for i in ordered_positions_2:\n",
        "        X_2.append(img_2[i[0], i[1], ::])\n",
        "    X_2 = np.array(X_2, copy=False)\n",
        "\n",
        "    X_2 = scaler.fit_transform(X_2)\n",
        "    labels_test = cls.predict(X_2)\n",
        "\n",
        "    predictions_map_test = np.zeros(labels_test.shape).reshape(height, width)\n",
        "    for (y, x), pred in zip(ordered_positions_2, labels_test):\n",
        "        predictions_map_test[y, x] = pred\n",
        "\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "\n",
        "    predictions_map_test = cv2.morphologyEx(predictions_map_test, cv2.MORPH_OPEN, kernel, iterations = 1)\n",
        "    #predictions_map_test = cv2.morphologyEx(predictions_map_test, cv2.MORPH_CLOSE, kernel, iterations = 1)\n",
        "\n",
        "    ax.imshow(img_2[:,:,::-1])\n",
        "    ax.set_title('Source')\n",
        "    ax.grid(False)\n",
        "\n",
        "    predictions_map_test_all.append(predictions_map_test)\n",
        "    sns.heatmap(predictions_map_test, ax=ax1)\n",
        "\n",
        "    n = (predictions_map_test == 1).sum()\n",
        "    n = round(n*0.0005948, 2)      # computing the deforested square\n",
        "    square.append(n)\n",
        "\n",
        "    ax1.axis('off')\n",
        "    ax1.set_title(f'Deforestation square = {n} ha');\n",
        "\n",
        "    j += 2\n",
        "    k += 2\n",
        "\n",
        "plt.show()\n",
        "end = timer()\n",
        "time = round(end - start, 2)\n",
        "total_square = round(sum(square), 2)\n",
        "print(f'{cls.__class__.__name__}, time:{time}, total square:{total_square}ha')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E9SZbmfvw9Zu",
      "metadata": {
        "id": "E9SZbmfvw9Zu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
